## ğŸ“– Contexte

Kayak est un moteur de recherche de voyages appartenant Ã  Booking Holdings.  
Le marketing a identifiÃ© un besoin fort : **70% des utilisateurs aimeraient plus dâ€™informations fiables sur leur destination**.  

Lâ€™objectif est de crÃ©er une application capable de :
- Recommander les **meilleures destinations** (top-5 villes en France) selon la mÃ©tÃ©o.
- Recommander les **meilleurs hÃ´tels** (top-20) selon Booking.com.
- Visualiser ces rÃ©sultats sur des **cartes interactives**.

## ğŸ¯ Objectifs

1. **Scraper les donnÃ©es destinations** :
   - RÃ©cupÃ©rer coordonnÃ©es GPS via **Nominatim** (API gratuite).
   - RÃ©cupÃ©rer mÃ©tÃ©o via **OpenWeatherMap API**.
   - DÃ©finir des critÃ¨res pour estimer la "mÃ©tÃ©o idÃ©ale" (pluie, tempÃ©rature, humiditÃ©, etc.).

2. **Scraper Booking.com** :
   - Nom, URL, coordonnÃ©es, score utilisateur, description des hÃ´tels.

3. **Stockage et ETL** :
   - Stocker les donnÃ©es brutes en CSV dans un **Data Lake (AWS S3)**.
   - CrÃ©er une base SQL (AWS RDS), nettoyer les donnÃ©es, les charger dedans.

4. **Visualisation** :
   - CrÃ©er deux cartes (Plotly) :
     - **Top-5 villes** (meilleure mÃ©tÃ©o).
     - **Top-20 hÃ´tels**.

## ğŸ› ï¸ QualitÃ© & bonnes pratiques

- **ReproductibilitÃ©** :  
  - Fixer les seeds (numpy, sklearn) pour assurer la mÃªme sÃ©lection de top villes.  
  - Sauvegarder les CSV intermÃ©diaires (avant/aprÃ¨s nettoyage).  

- **Industrialisation** :  
  - PrÃ©voir un pipeline ETL (Airflow ou Prefect) pour automatiser : scraping â†’ stockage â†’ nettoyage â†’ chargement RDS.  
  - DÃ©ploiement dans un conteneur Docker pour faciliter la portabilitÃ©.  

- **SÃ©curitÃ© & conformitÃ©** :  
  - Ne pas exposer les `API_KEY` en clair dans le code (utiliser `.env`).  
  - Respecter les rÃ¨gles dâ€™utilisation des APIs et du scraping.  


